{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CBAStats.Player import *\n",
    "# from CBAStats.Team import *\n",
    "# from CBAStats.Player import stats_output\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# import lxml.html as lh\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url, encoding='UTF-8', header={\n",
    "            'User-Agent': r'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                          r'Chrome/41.0.2227.1 Safari/537.36'}):\n",
    "    session = requests.Session()\n",
    "    base_url = url\n",
    "    response = session.get(base_url, headers=header)\n",
    "    response.encoding = encoding\n",
    "    page_content = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 链接中有几个参数，qleagueid是赛季，qmonth是月，qteamid是球队\n",
    "# 空出qmonth和qteamid则可以无差别选取某赛季的所有比赛\n",
    "# qleagueid并不是逐一递增或递减的，如20192020赛季是205，20182019是198\n",
    "\n",
    "def get_params(default_schedule_url = \"http://cba.sports.sina.com.cn/cba/schedule/all/\"):\n",
    "    \"\"\"\n",
    "    从赛程页爬取赛季，月，球队的可能参数值。\n",
    "    从可能的参数值里选取想要爬取的赛季，月，球队等，并用get_url函数拼凑出目标url。\n",
    "    \"\"\"\n",
    "    param_html_list = get_page_content(url=default_schedule_url).find_all('select')\n",
    "    param_dict = {}\n",
    "\n",
    "    for param in param_html_list:\n",
    "        options = {}\n",
    "        for option in param.find_all('option'):\n",
    "            options[option.text] = option['value']\n",
    "        param_dict[param['name']] = options\n",
    "    \n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_url(leagueid = '19-20',month = '全部',teamid ='全部'):\n",
    "\n",
    "    \"\"\"\n",
    "    此函数用于拼凑想要爬取的目标url。\n",
    "    \n",
    "    链接中有几个参数，qleagueid是赛季，qmonth是月，qteamid是球队。\n",
    "    qleagueid并不是逐一递增或递减的，如20192020赛季是205，20182019是198。\n",
    "    \n",
    "    \"\"\"\n",
    "    param_dict = get_params(default_schedule_url = \"http://cba.sports.sina.com.cn/cba/schedule/all/\")\n",
    "    qleagueid=param_dict['qleagueid'][leagueid]\n",
    "    qmonth=param_dict['qmonth'][month]\n",
    "    qteamid=param_dict['qteamid'][teamid]\n",
    "    scrape_url = f\"http://cba.sports.sina.com.cn/cba/schedule/all/?qleagueid={qleagueid}&qmonth={qmonth}&qteamid={qteamid}\"\n",
    "    \n",
    "    return scrape_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_schedule(season = '19-20',month = '全部',teamid ='全部', \n",
    "                    only_show_params = False,param_url = \"http://cba.sports.sina.com.cn/cba/schedule/all/\"):\n",
    "    \"\"\"\n",
    "    此函数用于爬取赛程和详细数据的链接，并存入CBA_Data.Staging_Schedules\n",
    "    \n",
    "    请注意，season(网页使用的参数是qleagueid)，month，team参数值是有限定值的。\n",
    "    可通过运行scrape_schedule(only_show_params = False)来查询可用的参数。如果only_show_params=True那么本函数不会爬取赛程数据，只会显示可用参数。\n",
    "    \n",
    "    参数中，season(qleagueid)是赛季，qmonth是月，qteamid是球队。\n",
    "    season(qleagueid)，如20192020赛季是205，20182019是198。\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    season:\n",
    "    month:\n",
    "    teamid:\n",
    "    only_show_params:\n",
    "    param_url:\n",
    "    \"\"\"\n",
    "    \n",
    "    param_dict = get_params(default_schedule_url = param_url)\n",
    "    \n",
    "    if only_show_params:\n",
    "        return param_dict\n",
    "    \n",
    "    # 拼凑出目标url\n",
    "    schedule_url = get_url(leagueid = season,month = month,teamid =teamid)\n",
    "    \n",
    "    # 爬取整张页面html\n",
    "    page_content = get_page_content(url=schedule_url)\n",
    "\n",
    "    # 赛程页面共有两张表\n",
    "    # 第一张表是当前轮次比赛\n",
    "    # 第二张表才是该赛季所有比赛\n",
    "\n",
    "    # 爬取整张表的html\n",
    "    target_table = page_content.find_all(\"table\")[1]\n",
    "\n",
    "    # 获取表头\n",
    "    headers = [th.text for th in target_table.find('thead').find_all('th')]\n",
    "\n",
    "    # 获取表格数据的html\n",
    "    tbody = target_table.find('tbody')\n",
    "\n",
    "    # 获取表格每行的html，存入list\n",
    "    trs = tbody.find_all('tr')\n",
    "    \n",
    "    # 用于存储文本的list\n",
    "    text_list =[]\n",
    "    # 用于存储链接的list\n",
    "    link_list = []\n",
    "\n",
    "    for tr in trs:\n",
    "        # 从每行中获取每一单元格的html\n",
    "        tds = tr.find_all('td')\n",
    "        for td in tds:\n",
    "            # 获取每单元格的纯文本内容\n",
    "            cell_text = str(td.text).strip()\n",
    "            # 单元格内若无链接则为空字符\n",
    "            cell_link = ''\n",
    "            if td.find('a',href=True):\n",
    "                # 单元格内存在链接则保存\n",
    "                cell_link = td.find('a',href=True)['href'].strip()\n",
    "            text_list.append(cell_text)\n",
    "            link_list.append(cell_link)\n",
    "    \n",
    "    # 分别将文本和链接保存在两个dataframe中，最后再横向合并\n",
    "    # 链接的dataframe在column header后加上“_link“后缀\n",
    "    # 因此会有空白列，此处不删除是考虑到未来可能会有新内容\n",
    "    text_list = np.reshape(text_list, [-1, 10])\n",
    "    link_list = np.reshape(link_list, [-1, 10])\n",
    "    df_schedule_text = pd.DataFrame(data=text_list, columns=headers)\n",
    "    df_schedule_link = pd.DataFrame(data=link_list, columns=[header + '_link' for header in headers])\n",
    "\n",
    "    df_schedule_full = pd.merge(df_schedule_text, df_schedule_link, left_index=True, right_index=True)\n",
    "\n",
    "    df_schedule_full['SinaGame_ID'] = df_schedule_full['统计_link'].apply(lambda x: re.findall('show[/](\\d+)[/]', x)[0])\n",
    "    df_schedule_full['客队ID'] = df_schedule_full['客队'].apply(lambda x: param_dict['qteamid'][x])\n",
    "    df_schedule_full['主队ID'] = df_schedule_full['主队'].apply(lambda x: param_dict['qteamid'][x])\n",
    "    df_schedule_full['日期'] = pd.to_datetime(df_schedule_full['日期'])\n",
    "       \n",
    "    return df_schedule_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schedule():\n",
    "    \n",
    "    user_name = 'master'\n",
    "    passcode = 'Pw#cbashuju0131'\n",
    "    endpoint = 'cbashuju.ctkaehd5rxxe.us-east-1.rds.amazonaws.com'\n",
    "    database = 'CBA_Data'\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{passcode}@{endpoint}/{database}')\n",
    "    connection= engine.connect()\n",
    "\n",
    "    # df.to_sql(name='Schedules',con=connection,index=False,if_exists='replace')\n",
    "    df = pd.read_sql(\"select * from CBA_Data.Schedules\", connection)\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "def get_staging_schedule():\n",
    "    \n",
    "    user_name = 'master'\n",
    "    passcode = 'Pw#cbashuju0131'\n",
    "    endpoint = 'cbashuju.ctkaehd5rxxe.us-east-1.rds.amazonaws.com'\n",
    "    database = 'CBA_Staging'\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{passcode}@{endpoint}/{database}')\n",
    "    connection= engine.connect()\n",
    "\n",
    "    # df.to_sql(name='Schedules',con=connection,index=False,if_exists='replace')\n",
    "    df = pd.read_sql(\"select * from CBA_Staging.Schedules\", connection)\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "def load_schedule_into_staging(scraped_schedule):\n",
    "    # 写入数据库Staging_Schedule\n",
    "    user_name = 'master'\n",
    "    passcode = 'Pw#cbashuju0131'\n",
    "    endpoint = 'cbashuju.ctkaehd5rxxe.us-east-1.rds.amazonaws.com'\n",
    "#     database = 'CBA_Data'\n",
    "    database = 'CBA_Staging'\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{passcode}@{endpoint}/{database}')\n",
    "    connection= engine.connect()\n",
    "\n",
    "    scraped_schedule.to_sql(name='Schedules',con=connection,index=False,if_exists='replace')\n",
    "    connection.close()\n",
    "\n",
    "def clean_staging_schedule():\n",
    "    \n",
    "    # query to clean-up staging schedule\n",
    "    \n",
    "    user_name = 'master'\n",
    "    passcode = 'Pw#cbashuju0131'\n",
    "    endpoint = 'cbashuju.ctkaehd5rxxe.us-east-1.rds.amazonaws.com'\n",
    "    database = 'CBA_Staging'\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{passcode}@{endpoint}/{database}')\n",
    "    with engine.connect() as connection:\n",
    "        with connection.begin():\n",
    "            # delete未开始，没比分的比赛\n",
    "            connection.execute(\"\"\"\n",
    "            DELETE FROM CBA_Staging.Schedules\n",
    "            WHERE 比分='VS';\n",
    "                               \"\"\")\n",
    "            \n",
    "            # delete已经scrape过的比赛\n",
    "            connection.execute(\"\"\"\n",
    "            DELETE\n",
    "            FROM CBA_Staging.Schedules\n",
    "            WHERE CBA_Staging.Schedules.SinaGame_ID IN (\n",
    "            SELECT SinaGame_ID\n",
    "            FROM CBA_Data.Schedules\n",
    "            );\n",
    "\n",
    "                               \"\"\")\n",
    "            \n",
    "            \n",
    "            # delete重复比赛\n",
    "            connection.execute(\"\"\"\n",
    "            DELETE\n",
    "            FROM CBA_Staging.Schedules\n",
    "            WHERE EXISTS (\n",
    "            SELECT 1\n",
    "            FROM  CBA_Data.Schedules prod\n",
    "            WHERE prod.主队=CBA_Staging.Schedules.主队\n",
    "            AND prod.主队=CBA_Staging.Schedules.主队\n",
    "            AND prod.日期=CBA_Staging.Schedules.日期\n",
    "            );\n",
    "                               \"\"\")\n",
    "            \n",
    "            # scrape完的比赛insert到CBA_Data.Schedules\n",
    "            connection.execute(\"\"\"\n",
    "            INSERT into CBA_Data.Schedules\n",
    "            SELECT *\n",
    "            FROM CBA_Staging.Schedules\n",
    "            WHERE SinaGame_ID not in (\n",
    "            SELECT SinaGame_ID\n",
    "            FROM CBA_Data.Schedules\n",
    "            ) and \n",
    "            SinaGame_ID in (\n",
    "            SELECT SinaGame_ID\n",
    "            FROM CBA_Data.PlayerStatsPerGame\n",
    "            );\n",
    "                               \"\"\")\n",
    "            # 删除已scrape完的比赛，且已经insert到CBA_Data.Schedules的比赛\n",
    "            connection.execute(\"\"\"\n",
    "            DELETE FROM  CBA_Staging.Schedules\n",
    "            WHERE SinaGame_ID in (\n",
    "            SELECT SinaGame_ID\n",
    "            FROM CBA_Data.Schedules\n",
    "            ) and \n",
    "            SinaGame_ID in (\n",
    "            SELECT SinaGame_ID\n",
    "            FROM CBA_Data.PlayerStatsPerGame\n",
    "            );\n",
    "                               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coach(html):\n",
    "    coach = re.findall('主教练：(.*?)领队', html)\n",
    "    return coach\n",
    "\n",
    "\n",
    "def get_lingdui(html):\n",
    "    lingdui = re.findall('领队：(.*?)<', html)\n",
    "    return lingdui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_made_attempt(df_orig):\n",
    "    \"\"\"\n",
    "    函数用于删除投篮命中率,split ”2分中-投“\n",
    "    \"\"\"\n",
    "    df = df_orig.copy()\n",
    "    for col_name in list(filter(lambda x: '-' in x, df.columns.tolist())):\n",
    "        orig_col = col_name\n",
    "        col_made = re.findall('(.*)中-投', col_name)[0] + '中'\n",
    "        col_attempt = re.findall('(.*)中-投', col_name)[0] + '投'\n",
    "        df[[col_made, col_attempt]] = df[orig_col].str.split('-', expand=True)\n",
    "        df[col_attempt] = df[col_attempt].apply(lambda x: re.sub('[(].*[)]', '', x))\n",
    "        \n",
    "        df[col_made] = pd.to_numeric(df[col_made])\n",
    "        df[col_attempt] = pd.to_numeric(df[col_attempt])\n",
    "        \n",
    "        df.drop(columns=orig_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_games(schedule_to_scrape):\n",
    "    df_list = []\n",
    "\n",
    "    for index,row in schedule_to_scrape.iterrows():\n",
    "\n",
    "        detail_url = row['统计_link']\n",
    "        page_content = get_page_content(detail_url, encoding='GB2312')\n",
    "\n",
    "        for table_num,table in enumerate(page_content.find_all(\"table\")[:2]):\n",
    "            stats_headers = [th.text for th in table.find('thead').find_all('th')]\n",
    "            stats_headers.insert(0,'球员_link')\n",
    "            # extract details\n",
    "            all_trs = []\n",
    "            for tr in table.find('tbody').find_all('tr'):\n",
    "                # 抓取行(tr)\n",
    "                all_tds=[]\n",
    "                # 在每一行中抓取每一格(td)\n",
    "                for td in tr.find_all('td'):\n",
    "                    # get 球员link\n",
    "                    if td.find('a',href=True):\n",
    "                        all_tds.append(td.find('a',href=True)['href'].strip())\n",
    "                    all_tds.append(td.text.strip().replace(' ','').replace('\\n',''))\n",
    "                all_trs.append(all_tds)\n",
    "\n",
    "            team_df =pd.DataFrame(all_trs,columns=stats_headers)\n",
    "\n",
    "            # 删除球队行\n",
    "            team_df.drop(team_df.loc[team_df['号码'] == '--'].index, inplace=True)\n",
    "\n",
    "            # clean data frame\n",
    "\n",
    "            # get 球员ID \n",
    "            # 暂不提取球员ID，有时新球员加入，新浪更新不及时，可能会没有球员ID，导致error\n",
    "            # team_df['球员ID'] = team_df['球员_link'].apply(lambda x: int(re.findall('show[/](\\d+)[/]', x)[0]))\n",
    "\n",
    "            # team_df['号码'] = team_df['号码'].astype(str)\n",
    "            team_df['轮次'] = row['轮次']\n",
    "            team_df['SinaGame_ID']=row['SinaGame_ID']\n",
    "            if table_num==0:\n",
    "                # 主队table\n",
    "                team_df['球队ID'] = row['主队ID']\n",
    "                team_df['对手ID'] = row['客队ID']\n",
    "                team_df['球队'] = row['主队']\n",
    "                team_df['对手'] = row['客队']\n",
    "            else:\n",
    "                # 客队table\n",
    "                team_df['球队ID'] = row['客队ID']\n",
    "                team_df['对手ID'] = row['主队ID']\n",
    "                team_df['球队'] = row['客队']\n",
    "                team_df['对手'] = row['主队']\n",
    "\n",
    "            team_df['地点'] = row['地点']\n",
    "\n",
    "            df_list.append(team_df)\n",
    "        if ((index+1)%10==0)|(index==0):\n",
    "            print('已爬取', index+1,'场比赛', datetime.datetime.now())\n",
    "        time.sleep(np.random.rand() * 4)\n",
    "\n",
    "    print('完成！')\n",
    "    games_stats = pd.concat(df_list, ignore_index=True)\n",
    "    games_stats = split_made_attempt(games_stats)\n",
    "    games_stats[['出场时间', '进攻篮板', '防守篮板', '助攻', '犯规', '抢断',\n",
    "               '失误', '盖帽', '扣篮', '被侵', '2分中', '2分投', \n",
    "               '3分中', '3分投', '罚球中',\n",
    "               '罚球投']] = games_stats[['出场时间', '进攻篮板', '防守篮板', '助攻', '犯规', '抢断',\n",
    "                                   '失误', '盖帽', '扣篮', '被侵', '2分中', '2分投', \n",
    "                                   '3分中', '3分投', '罚球中','罚球投']].astype(int)\n",
    "    # 计算得分\n",
    "    games_stats['得分'] = games_stats['2分中']*2+games_stats['3分中']*3+games_stats['罚球中']\n",
    "    games_stats['号码'] = games_stats['号码'].astype(str)\n",
    "    # games_stats['球队ID'] = games_stats['球队ID'].astype(str)\n",
    "    # games_stats['对手ID'] = games_stats['对手ID'].astype(str)\n",
    "    games_stats['首发'] = games_stats['首发'].apply(lambda x: re.sub('是', '1', x))\n",
    "    games_stats['首发'] = games_stats['首发'].apply(lambda x: re.sub('否', '0', x))\n",
    "    games_stats['首发'] = games_stats['首发'].astype(int)\n",
    "    \n",
    "    return games_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_details(df):\n",
    "    # 写入数据库Staging_Schedule\n",
    "    user_name = 'master'\n",
    "    passcode = 'Pw#cbashuju0131'\n",
    "    endpoint = 'cbashuju.ctkaehd5rxxe.us-east-1.rds.amazonaws.com'\n",
    "    database = 'CBA_Data'\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{passcode}@{endpoint}/{database}')\n",
    "    connection= engine.connect()\n",
    "\n",
    "    df.to_sql(name='PlayerStatsPerGame',con=connection,index=False,if_exists='append')\n",
    "\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>轮次</th>\n",
       "      <th>日期</th>\n",
       "      <th>主队</th>\n",
       "      <th>比分</th>\n",
       "      <th>客队</th>\n",
       "      <th>战报</th>\n",
       "      <th>统计</th>\n",
       "      <th>组图</th>\n",
       "      <th>地点</th>\n",
       "      <th>电视</th>\n",
       "      <th>...</th>\n",
       "      <th>比分_link</th>\n",
       "      <th>客队_link</th>\n",
       "      <th>战报_link</th>\n",
       "      <th>统计_link</th>\n",
       "      <th>组图_link</th>\n",
       "      <th>地点_link</th>\n",
       "      <th>电视_link</th>\n",
       "      <th>SinaGame_ID</th>\n",
       "      <th>客队ID</th>\n",
       "      <th>主队ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [轮次, 日期, 主队, 比分, 客队, 战报, 统计, 组图, 地点, 电视, 轮次_link, 日期_link, 主队_link, 比分_link, 客队_link, 战报_link, 统计_link, 组图_link, 地点_link, 电视_link, SinaGame_ID, 客队ID, 主队ID]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_schedule = scrape_schedule()\n",
    "load_schedule_into_staging(scraped_schedule)\n",
    "clean_staging_schedule()\n",
    "schedule_to_scrape = get_staging_schedule()\n",
    "schedule_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_stats=scrape_games(schedule_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_details(games_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_staging_schedule()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
